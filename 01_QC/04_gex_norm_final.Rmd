---
title: "GEX Normalization"
author: "kou"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, include=T, warning = F, message=F, eval=F)
```

```{r libraries, include=F}
library(Seurat)
library(tidyverse)
library(ggpubr)
library(tricycle)
library(shiny)
library(clustree)
library(qs)
library(reticulate)

# always set seed!
set.seed(105)

options(future.globals.maxSize = 4000 * 1024^2)

# set python
use_python("/g/scb/zaugg/kou/projects/composite/analysis/sc_py_env/bin")
use_virtualenv("/g/scb/zaugg/kou/projects/composite/analysis/sc_py_env")
```

```{r splitSeuratObj}
# import
# object was merged during filtering to match cells kept after QC step in ATAC-seq
merged = readRDS("./01_QC/rds/03_seur_keep.rds")
merged_meta = merged@meta.data

# split merged datasets
merged$Sample = gsub("#.*","",merged$cell_ids)
split_seur = SplitObject(merged, split.by = "Sample")
```

### Goals:

-   Perform 2 different approaches of normalization, both BEFORE merging
    data sets:
    -   log-normalize/scale
    -   SCTransform
-   This preprint demonstrated that normalization before merging always
    outperforms normalization after merging
    (<https://www.biorxiv.org/content/10.1101/2021.08.18.456898v1.full.pdf>,
    figure 5).
-   Additional notes on when to merge datasets (before/after
    SCTransform):
    -   <https://www.biostars.org/p/9516696/>
    -   <https://satijalab.org/seurat/articles/integration_introduction.html>

## 1. Log-Normalizing & Scaling RNA counts

-   Normalization (from Seurat vignette):
    -   normalizes the feature expression measurements for each cell by
        the total expression, multiplies this by a scale factor (10,000
        by default), and log-transforms the result
-   Scaling (from Seurat vignette):
    -   Shifts the expression of each gene, so that the mean expression
        across cells is 0
    -   Scales the expression of each gene, so that the variance across
        cells is 1
    -   Can regress out variables here! Just like in SCTransform
    -   This step gives equal weight in downstream analyses, so that
        highly-expressed genes do not dominate
    -   The results of this are stored in `pbmc[["RNA"]]@scale.data`
-   Perform prior to adding cell cycle scores to see cell cycle genes
    (and/or other features like mt ratio) explain unwanted variation

```{r logNorm}
# get seurat gene list
ccGenes = cc.genes.updated.2019

# normalize and find variable features
split_logNorm = lapply(split_seur, FUN = function(x){
    x = NormalizeData(x, 
                      normalization.method = "LogNormalize", 
                      scale.factor = 10000, # default
                      verbose = F) 
    
    # do before scaling
    x = FindVariableFeatures(x, 
                             selection.method = "vst", 
                             nfeatures = 2000,
                             verbose = F)
    
    x = ScaleData(x, 
                  features = allGenes,
                  verbose = F)
    
    return(x)
})
```

### Adding cell cycle scores

-   After normalizing counts, can add cell cycle score multiple ways
-   Seurat uses a list generated from Tirosh, et al to separate S genes
    from G2M
    genes:(<https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4944528/>)
-   Other packages like `tricycle`
    (<https://bioconductor.org/packages/release/bioc/html/tricycle.html>)
    uses a different gene list that can separate more cell cycle phases.
    Can compare cell cycle scoring \* "users can approximately relate
    0.5pi to be the start of S stage, pi to be the start of G2M stage,
    1.5pi to be the middle of M stage, and 1.75pi-0.25pi to be G1/G0
    stage."
-   Also adds cell cycle stages from Schwabe method
    <https://www.embopress.org/doi/full/10.15252/msb.20209946>
    -   gene list they used:
        <https://www.molbiolcell.org/doi/10.1091/mbc.02-02-0030>

```{r addCellCycleGenes, messsage=F, warning=F}
# add score, which is similar to AddModuleScore()
split_logNorm = map(split_logNorm, ~ CellCycleScoring(.x,
                                                      g2m.features = ccGenes$g2m.genes,
                                                      s.features = ccGenes$s.genes))

# also add tricycle score
# create function
add_tri = function(seu_obj){
  # get data of active assay
  normCounts = GetAssayData(seu_obj, slot = "data")
  
  # phases are determined by multiples of pi from tricycle method
  tricycle_phases = estimate_cycle_position(normCounts, 
                                            gname.type = "SYMBOL",
                                            species = "human")
  
  # implementation of Schwabe method using RevelioGeneList (see fxn for more details)
  schwabe_phases = estimate_Schwabe_stage(normCounts, 
                                          gname.type = "SYMBOL",
                                          species = "human")
  
  # add to metadata of seuObj
  seu_obj$tricycle = tricycle_phases
  seu_obj$schwabe_phases = schwabe_phases
  
  return(seu_obj)
}

# add other cell cycle scores
split_logNorm  = lapply(split_logNorm, add_tri)
```

### PCA Analysis

-   Determine dimensionality of data and maximum number of PCs to use
    for clustering
-   Determine features that explain the most variance along a PC
    (loadings)
-   Determine if certain covariates (mt ratio, cell cycle, etc) explain
    variation along top PCs
    -   These can be regressed out during scaling! (or during
        SCTransform)
-   More info:
    <https://hbctraining.github.io/scRNA-seq/lessons/elbow_plot_metric.html>
    <https://github.com/hbctraining/scRNA-seq_online/blob/master/lessons/06_SC_SCT_normalization.md>

```{r rnaPCA}
# run PCA, might need to increase # pcs (npcs) later
split_logNorm = map(split_logNorm, ~ RunPCA(.x,
                                            npcs = 30,
                                            reduction.name = "rnaPCA",
                                            verbose = F)) 

# create function to get % explained variance (returns vector)
# can also use to label PCA axes
get_pctVar = function(seuObj){
  pct = seuObj[["rnaPCA"]]@stdev / sum(seuObj[["rnaPCA"]]@stdev) * 100
  return(pct)
}

pcVar = lapply(split_logNorm, get_pctVar)

# get cumulative sums to quantitatively determine dimensionality
cumsum = lapply(pcVar, cumsum)

# determine the first PC that has cum variance of 90% & explains < 5% total variance
# this determines dimensionality of data
whichPC = map2(pcVar,cumsum, ~ which(.y > 90 & .x < 5)[1])
whichPC
```

TO DO: add scree/elbow plot

```{r scree}

```

### Plot PCA

```{r pcaEmbeddings}
# get pca embeddings
pcaEmbeds = lapply(split_logNorm, function(seuObj){
  seuObj[["rnaPCA"]]@cell.embeddings %>%
    as_tibble(rownames = "cellID")
  })

# get metadata
meta = lapply(split_logNorm, function(seuObj){
  seuObj@meta.data %>%
    as_tibble(rownames = "cellID") %>%
    select(!c("cell_ids","Sample","orig.ident"))
  })

# reformat for plotting2
pcaEmbeds = map2(pcaEmbeds, meta, ~ left_join(.x, .y, by = "cellID"))

# get color code choices
color_by = colnames(pcaEmbeds[[1]])[!grepl("PC_|cellID",colnames(pcaEmbeds[[1]]))]
```

TO DO: create better functions, add % variation explained by PC to axis
in pcVar object

TO DO: correlate features to PC components!

```{r shinyPCA}
ui = fluidPage(
  titlePanel("PCA, log-normalized and scaled counts"),
  sidebarLayout(
    
    # what to include in side panel
    sidebarPanel(
      
      # select variable of interest
      selectInput(inputId = "color_by", 
                  label = "Select Color Code:",
                  choices = color_by),
      
      # select PCs
      selectInput(inputId = "x_PC",
                  label = "Select x-axis PC",
                  choices = paste0("PC_",1:15)),
      selectInput(inputId = "y_PC",
                  label = "Select y-axis PC",
                  choices = paste0("PC_",1:15))
    ),
    
    # plots
    mainPanel(plotOutput(outputId = "LN0025_pca"),
              plotOutput(outputId = "LN0177_pca"),
              plotOutput(outputId = "LN0193_pca"),
              plotOutput(outputId = "LN0438_pca"))
  )
)

serv = function(input, output){
  
  # ggplot fxn 
  plotPCA = function(df){
    ggplot(df, aes_string(input$x_PC,input$y_PC)) +
      geom_jitter(aes(color = .data[[input$color_by]]), size = 0.5) +
      theme_bw() +
      theme(aspect.ratio = 3/3,
            panel.grid = element_blank()) +
      scale_color_viridis_c(option = "plasma")
  }
  
  # LN0025
  output$LN0025_pca = renderPlot({
    plotPCA(pcaEmbeds$LN0025)+
      labs(title = "LN0025")
  })
  
  # LN0177
  output$LN0177_pca = renderPlot({
    plotPCA(pcaEmbeds$LN0177)+
      labs(title = "LN0177")
  })
  
  # LN0193
  output$LN0193_pca = renderPlot({
    plotPCA(pcaEmbeds$LN0193)+
      labs(title = "LN0193")
  })
  
  # LN0438
  output$LN0438_pca = renderPlot({
    plotPCA(pcaEmbeds$LN0438)+
      labs(title = "LN0438")
  })
}

shinyApp(ui = ui, server = serv)
```

**Based on PCA results:**

-   Seems like cells do separate based on cell cycle / tricycle scores
    (PCs 3 and 4, \~ 5% total variation)
-   Mitochondrial gene ratio didn't seem to have a huge impact on
    separating samples, but it could be because of previous filtering
    steps (cutoff = 0.15, maybe too strict?).
-   Seurat cell cycle regression recommendation: "we suggest regressing
    out the difference between the G2M and S phase scores. This means
    that signals separating non-cycling cells and cycling cells will be
    maintained, but differences in cell cycle phase amongst
    proliferating cells (which are often uninteresting), will be
    regressed out of the data."
-   **For this version, will keep ALL cell cycle scores to try to
    resolve B cell subclusters.**

```{r S.G2M.score, include=F}
# new cc_diff score for sct regression
split_logNorm = lapply(split_logNorm, function(seuObj){
  seuObj$cc_diff = seuObj$S.Score - seuObj$G2M.Score
  return(seuObj)
})
```

### TO DO: Rescaling data with variable regression

-   if you want to regress out variables in future (ratio_mt or cc_diff
    score), repeat `ScaleData()` with `variables.to.regress` parameter
    here
-   need to repeat PCA if so!!

### UMAP Reduction

-   create `rnaUMAP` umap embedding from log-normalized and scaled RNA
    counts (will also create `sctUMAP` later with SCTransfrom normalized
    RNA counts
-   use clustree to identify optimal resolution for clustering

```{r pcaUMAP}
# run UMAP
split_logNorm = map(split_logNorm, ~ RunUMAP(.x,
                                             reduction.name = "rnaUMAP",
                                             reduction.key = "rnaUMAP_",
                                             reduction = "rnaPCA",
                                             dims = 1:26,
                                             verbose = F))
```

### Clustering

-   use `clustree` program to identify optimal resolution
-   one node with multiple incoming edges means data is over-clustered

```{r lognorm.clustering, out.width="50%", out.height="50%"}
# find neighbors
split_logNorm = map(split_logNorm, ~ FindNeighbors(.x, 
                                                   reduction = "rnaPCA",
                                                   dims = 1:26,
                                                   verbose = F))

# find appropriate resolution using leiden clustering
test_tree = map(split_logNorm, ~ FindClusters(.x,
                                              resolution = seq(0.25, 1.75, by = 0.25),
                                              algorithm = "4",
                                              method = "igraph", 
                                              random.seed = 1,
                                              verbose = F))

# plot to see which resolution is the best
lapply(1:4, FUN = function(x){
  # get metadata w/ cluster info
  df = test_tree[[x]]@meta.data
  
  # speficy columns with cluster info
  clustree(df, prefix = "RNA_snn_res.")+
    labs(title = names(test_tree)[[x]])
})
```

**Resolution based off of Clustree analysis:**

-   LN0025: 1
-   LN0177: 1.5
-   LN0193: 1.75
-   LN0438: 1 (or 0.75?)

Repeat clustering

```{r final.cluster.lognorm}
# based off of clustree
res = c(1,1.5,1.75,1)

# repeat clustering
split_logNorm = map2(split_logNorm, res, 
                     ~ FindClusters(.x,
                                    resolution = .y,
                                    algorithm = "4",
                                    method = "igraph",
                                    random.seed = 1,
                                    verbose = F))
```

### Plot UMAP from log-normalized RNA

```{r plot.rnaUMAP}
# quick plot
rnaUMAP = lapply(1:4, FUN = function(x){
  DimPlot(split_logNorm[[x]], 
          reduction = "rnaUMAP", 
          group.by = paste0("RNA_snn_res.",res[[x]]),
          pt.size = 0.05,
          label.size = 3,
          label = T) +
    theme(aspect.ratio = 3/3, 
          legend.position = "none") +
    labs(title = names(split_logNorm)[[x]])
})

rnaUMAP = ggarrange(plotlist = rnaUMAP)

ggsave("01_QC/figs/04_rnaUMAP_noCCreg.png",rnaUMAP)

rnaUMAP
```

```{r plot.rnaUMAP.ms4a1}
# quick plot
rnaUMAP_ms4a1 = lapply(1:4, FUN = function(x){
  FeaturePlot(split_logNorm[[x]], 
              features = "MS4A1",
              slot = "data",
              reduction = "rnaUMAP",
              pt.size = 0.05,
              label = F) +
    theme(aspect.ratio = 3/3) +
    labs(title = names(split_logNorm)[[x]])
})

rnaUMAP_ms4a1 = ggarrange(plotlist = rnaUMAP_ms4a1)

ggsave("01_QC/figs/04_rnaUMAP_ms4a1_noCCreg.png",rnaUMAP_ms4a1)

rnaUMAP_ms4a1
```

## 2. Normalize by SCTransform

-   In this version, did NOT regress out any variable
-   "SCT" assay is added to seurat object. log-normalized RNA can still
    be accessed in "RNA" assay

```{r SCTransform}
# DID NOT regress out cc_diff score
#use all genes (residual.features=NULL) to calc residuals
split_sct = map(split_logNorm, ~ SCTransform(.x,
                                             vst.flavor = "v2",
                                             residual.features = NULL))
```

### PCA analysis with SCTransformed counts

```{r sctPCA}
# redo PCA w/ SCT assay
split_sct = map(split_sct, ~ RunPCA(.x,
                                    npcs = 30,
                                    reduction.name = "sctPCA",
                                    reduction.key = "sctPC_",
                                    verbose = F))

# see % variance for each pc in sctPCA dimen reduc obj
sct_pcVar = lapply(split_sct, function(seuObj){
  pct = seuObj[["sctPCA"]]@stdev / sum(seuObj[["sctPCA"]]@stdev) * 100
  return(pct)
  })

# get cumulative sums to quantitatively determine dimensionality
sct_cumsum = lapply(sct_pcVar, cumsum)

# determine the first PC that has cum variance of 90%, but explains less than 5% (use for umap) 
whichPC = map2(sct_pcVar, sct_cumsum, ~ which(.y > 90 & .x < 5)[1])
whichPC
```

### sctUMAP

-   use "sctPCA" and dims 1:26

```{r sctUMAP}
split_sct = map(split_sct, ~ RunUMAP(.x,
                                     reduction.name = "sctUMAP",
                                     reduction.key = "sctUMAP_",
                                     reduction = "sctPCA",
                                     dims = 1:26,
                                     verbose = F))
```

### Clustering with sctPCA

```{r sct.clustering, include=T}
# find neighbors and clusters for visualization, use different resolutions
split_sct = map(split_sct, ~ FindNeighbors(.x,
                                           reduction = "sctPCA", 
                                           dims = 1:26,
                                           verbose = FALSE))

# find appropriate resolution using leiden clustering
# make sure default assay is SCT! 
test_tree2 = map(split_sct, ~ FindClusters(.x,
                                           resolution = seq(0.25, 1.75, by = 0.25),
                                           algorithm = "4",
                                           method = "igraph", 
                                           random.seed = 1,
                                           verbose = F))

# plot to see which resolution is the best
lapply(1:4, FUN = function(x){
  # get metadata w/ cluster info
  df = test_tree2[[x]]@meta.data
  
  # speficy columns with cluster info
  clustree(df, prefix = "SCT_snn_res.")+
    labs(title = names(test_tree2)[[x]])
})
```

**Resolution results of Clustree**

-   LN0025: 0.75 (1?)
-   LN0177: 0.5 (0.75?)
-   LN0193: 1
-   LN0438: 0.75

```{r final.cluster.sct}
# based off of clustree
res2 = c(0.75,0.5,1,0.75)

# repeat clustering
split_sct = map2(split_sct, res2, ~ FindClusters(.x,
                                                 resolution = .y,
                                                 algorithm = "4",
                                                 method = "igraph",
                                                 random.seed = 1,
                                                 verbose = F))

qsave(split_sct,"./01_QC/rds/04_split_sct_noCCreg.qs",nthreads = 16)
```

### Plot sctUMAP

```{r plot.sctUMAP}
# quick plot
sctUMAP = lapply(1:4, FUN = function(x){
  DimPlot(split_sct[[x]], 
          reduction = "sctUMAP", 
          group.by = paste0("SCT_snn_res.",res2[[x]]),
          pt.size = 0.05,
          label.size = 3,
          label = T) +
    theme(aspect.ratio = 3/3, 
          legend.position = "none") +
    labs(title = names(split_sct)[[x]])
})

sctUMAP = ggarrange(plotlist = sctUMAP)

ggsave("01_QC/figs/04_sctUMAP_noCCreg.png",sctUMAP)

sctUMAP
```

```{r plot.sctUMAP.ms4a1}
# quick plot
sctUMAP_ms4a1 = lapply(1:4, FUN = function(x){
  FeaturePlot(split_sct[[x]], 
              features = "MS4A1",
              slot = "data",
              reduction = "sctUMAP",
              pt.size = 0.05,
              label = F) +
    theme(aspect.ratio = 3/3) +
    labs(title = names(split_sct)[[x]])
})

sctUMAP_ms4a1 = ggarrange(plotlist = sctUMAP_ms4a1)

ggsave("01_QC/figs/04_sctUMAP_ms4a1_noCCreg.png",sctUMAP_ms4a1)

sctUMAP_ms4a1
```
